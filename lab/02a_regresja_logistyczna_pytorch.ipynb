{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import checker\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstęp do PyTorcha\n",
    "* PyTorch to biblioteka do uczenia maszynowego, w szczególności głębokiego.\n",
    "\n",
    "**Interfejs** jest bardzo podobny do numpy, z wyjątkiem pewnych zmian:\n",
    "* Zamiast `numpy.ndarray` naszym podstawowym obiektem będzie teraz `torch.Tensor`. Tensor, czyli uogólnienie macierzy do wyższych wymiarów.\n",
    "* Jeśli chcemy zsumować macierz `A` po pierwszym wymiarze, w numpy zrobilibyśmy `A.sum(axis=0)`. W PyTorch zamiast tego używamy argumentu `dim`: `A.sum(dim=0)`.\n",
    "* Zamiast `np.concatenate` jest `torch.cat`.\n",
    "* Zamiast `np.power` jest `torch.pow`.\n",
    "* I tym podobne.\n",
    "\n",
    "W nowszych wersjach PyTorcha [pojawia się coraz więcej podobieństw do NumPy](https://github.com/pytorch/pytorch/issues/38349), co pozwala m. in. używać argumentu `axis` wymiennie z `dim`. Przy przechodzeniu między tymi dwiema bibliotekami warto jednak uważać, gdyż nie wszystkie metody zachowują się w identyczny sposób.\n",
    "\n",
    "\n",
    "\n",
    "Przejście z `numpy.ndarray` do `torch.Tensor` (i na odwrót) jest bardzo proste:\n",
    "* `A (numpy.ndarray) -> B (torch.Tensor)`: `B = torch.from_numpy(A)`\n",
    "* `B (torch.Tensor) -> A (numpy.ndarray)`: `A = B.numpy()`\n",
    "    \n",
    "Kluczowe różnice:\n",
    "* PyTorch **automatycznie liczy dla nas gradienty**. Nie musimy własnoręcznie liczyć na kartce wzoru na gradient a potem przepisywać go do programu.\n",
    "* PyTorch ma **wsparcie dla GPU**, co umożliwia szybkie obliczenia w sieciach neuronowych.\n",
    "\n",
    "Dobre materiały do nauki PyTorcha: [Deep Learning in 60 minutes](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html), [PyTorch Examples](https://github.com/pytorch/examples).\n",
    "\n",
    "Drobna uwaga - te tutoriale opisują abstrakcje takie jak `torch.nn.Module`, `torch.optim.SGD` czy `torch.utils.data`, którymi będziemy się zajmować od kolejnych zajęć. Na tych zajęciach spróbujemy zobaczyć, co PyTorch robi \"pod spodem\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatyczne różniczkowanie w PyTorchu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(\n",
    "    loss: Callable[[torch.Tensor, torch.Tensor, torch.Tensor | None], torch.Tensor],\n",
    "    X: torch.Tensor,\n",
    "    parameters: torch.Tensor,\n",
    "    y: torch.Tensor | None = None,\n",
    "    lr: float = 1e-6,\n",
    "    num_steps: int = int(1e4),\n",
    ") -> torch.Tensor:\n",
    "    for idx in range(num_steps):\n",
    "        # Informujemy PyTorcha, że chcemy dostać gradient po naszych parametrach\n",
    "        parameters.requires_grad = True\n",
    "\n",
    "        # Liczymy wartość funkcji kosztu.\n",
    "        loss_val = loss(X, parameters, y)\n",
    "\n",
    "        # Każemy PyTorchowi policzyć gradient\n",
    "        loss_val.backward()\n",
    "\n",
    "        # Wyciągamy gradient po parametrach\n",
    "        gradient = parameters.grad\n",
    "\n",
    "        # Wykonujemy krok metody spadku gradientu\n",
    "        with torch.no_grad():\n",
    "            parameters = parameters - lr * gradient\n",
    "\n",
    "    # Zwracamy najlepsze parametry\n",
    "    return parameters\n",
    "\n",
    "\n",
    "# Dziwna funkcja, której minimum będziemy chcieli znaleźć.\n",
    "def complex_fn(a: torch.Tensor, x: torch.Tensor, _: torch.Tensor | None = None) -> torch.Tensor:\n",
    "    y = a[0] / a[1] * torch.cos(a[0] * x**2 + a[1] * x - a[2])\n",
    "    z = torch.exp(-x) / (y + 3)\n",
    "    return -(z + y) + torch.exp(-x - 0.8)\n",
    "\n",
    "\n",
    "a = torch.tensor([3.0, 5.0, 1.0])\n",
    "x = torch.tensor(-4.0)\n",
    "result = gradient_descent(complex_fn, a, x, lr=2e-2, num_steps=int(2e4))\n",
    "\n",
    "utils.plot_torch_fn(complex_fn, a, x, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing datasets\n",
    "torch.manual_seed(5)\n",
    "\n",
    "# Regression dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes_X = torch.tensor(diabetes.data, dtype=torch.float32)\n",
    "diabetes_y = torch.tensor(diabetes.target, dtype=torch.float32)\n",
    "diabetes_w = torch.randn(diabetes_X.shape[1], dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "diabetes_data = (diabetes_X, diabetes_y, diabetes_w)\n",
    "\n",
    "\n",
    "# Multidimensional datasets\n",
    "dataset_5d = torch.randn([1000, 5], dtype=torch.float32)\n",
    "param_5d = torch.randn(5, requires_grad=True)\n",
    "\n",
    "dataset_20d = torch.randn([325, 20], dtype=torch.float32)\n",
    "param_20d = torch.randn(20, requires_grad=True)\n",
    "\n",
    "multi_datasets = [(dataset_5d, param_5d), (dataset_20d, param_20d)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1 (2 pkt.)\n",
    "\n",
    "Zaimplementuj w PyTorchu funkcje kosztu, które minimalizowaliśmy na wcześniejszych ćwiczeniach. Czyli konkretnie:\n",
    "* `mean_squared_error` (lab 02)\n",
    "* `mean_error` (lab 02)\n",
    "* `max_error` (lab 02)\n",
    "* `linear_regression_loss` (lab 03)\n",
    "* `regularized_regression_loss` (lab 03)\n",
    "\n",
    "Proszę te funkcje przekleić (ze swoich rozwiązań czy też oficjalnych) i przerobić tak, żeby przyjmowały `torch.Tensor` zamiast `np.ndarray` oraz zwracały `torch.Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.092079Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(X: torch.Tensor, theta: torch.Tensor) -> torch.Tensor:\n",
    "    ...\n",
    "\n",
    "\n",
    "checker.check_4_1_mse(mean_squared_error, multi_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.093345Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_error(X: torch.Tensor, theta: torch.Tensor) -> torch.Tensor:\n",
    "    ...\n",
    "\n",
    "\n",
    "checker.check_4_1_me(mean_error, multi_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.094568Z"
    }
   },
   "outputs": [],
   "source": [
    "def max_error(X: torch.Tensor, theta: torch.Tensor) -> torch.Tensor:\n",
    "    ...\n",
    "\n",
    "\n",
    "checker.check_4_1_max(max_error, multi_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.095649Z"
    }
   },
   "outputs": [],
   "source": [
    "def linear_regression_loss(X: torch.Tensor, w: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    ...\n",
    "\n",
    "\n",
    "checker.check_4_1_lin_reg(linear_regression_loss, diabetes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.096893Z"
    }
   },
   "outputs": [],
   "source": [
    "def regularized_regression_loss(X: torch.Tensor, w: torch.Tensor, y: torch.Tensor, alpha: float = 0.2) -> torch.Tensor:\n",
    "    ...\n",
    "\n",
    "\n",
    "checker.check_4_1_reg_reg(regularized_regression_loss, diabetes_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Część 1: Regresja logistyczna\n",
    "\n",
    "## Klasyfikacja\n",
    "\n",
    "Dzisiaj na zajęciach zajmiemy się problemem klasyfikacji. Podobnie do regresji liniowej jest to przykład uczenia nadzorowanego, ale zamiast przewidywać konkretną liczbę dla danej obserwacji, przewidujemy jego przynajeżność do jednej z *k* klas. Na tych zajęciach będziemy rozważać klasyfikacje binarną, czyli uczyć modele odpowiadające funkcji:\n",
    "\n",
    "$$ f(x) = y, \\quad y \\in \\{0,1\\} $$\n",
    "\n",
    "## Modele probabilistyczne i decyzyjne\n",
    "Przyjmujemy, że mamy zadanie klasyfikacji binarnej (dwie klasy). Na wykładzie poznaliśmy co najmniej dwie metody klasyfikacji:\n",
    "\n",
    "1. Support Vector Machine, który dla zadanego przykładu podaje nam po prostu jego przewidzianą klasę $y$\n",
    "2. Regresję logistyczną, która zwraca rozkład na klasach.\n",
    "\n",
    "SVM tym samym nie jest jednak w stanie powiedzieć nam jak bardzo pewny jest swojej decyzji, regresja logistyczna potrafi to osiągnąć. Na tej podstawie możemy stworzyć sobie następujący podział modeli klasyfikacyjnych:\n",
    "\n",
    "* **Modele decyzyjne** - są w stanie odpowiedzieć nam, jaki jest najbardziej prawdopodobna etykieta $y$ dla przykładu $x$, ale nie dają rozkładu prawdopodobieństwa.\n",
    "* **Modele probabilistyczne** - zadają nam rozkład na etykietach $p(y \\mid x)$, dzięki czemu dostajemy więcej informacji.\n",
    "\n",
    "**Pytanie:** Dlaczego może nas interesować cały rozkład prawdopodobieństwa zamiast najbardziej prawdopodobnej odpowiedzi?\n",
    "\n",
    "## Regresja logistyczna jako model probabilistyczny\n",
    "Chcielibyśmy stworzyć model, który otrzymując na wejściu $x$ będzie w stanie nam powiedzieć, jakie jest prawdopodobieństwo, że $y = 0$. Tzn, jeśli nasz model to funkcja $g(x)$, to nasza funkcja ma zadawać rozkład prawdopodobieństwa:\n",
    "\n",
    "$$g(x) = \\hat{p}(y = 1 \\mid x)$$\n",
    "\n",
    "Z tego możemy łatwo wyciągnąć prawdopodobieństwo, że zadany przykład ma etykietę $0$, tzn:\n",
    "$$ \\hat{p}(y = 0 \\mid x) = 1 - \\hat{p}(y = 1 \\mid x) = 1 - g(x) $$\n",
    "\n",
    "\n",
    "**Pytanie:** Kiedy będziemy mieli model zadający nam rozkład $\\hat{p}(y \\mid x)$, jak odpowiedzieć na pytanie \"jaka jest etykieta zadanego przykładu\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna na podstawie regresji liniowej\n",
    "\n",
    "**Problem:** Jak uzyskać probabilistyczny model klasyfikacyjny? Moglibyśmy użyć naszego modelu liniowego o postaci $f(x) = w^Tx + b$, ale ten model ma wadę: może przewidywać dowolne wartości ze zbioru liczb rzeczywistych, tzn. $f(x) \\in \\mathbb{R}$, natomiast z definicji prawdopodobieństwo $p(y=1) \\in [0, 1]$.\n",
    "\n",
    "*Uwaga: Wcześniej nasz model liniowy był postaci $f(x) = w^Tx$, teraz dodaliśmy jeszcze tzw. bias $b \\in \\mathbb{R}$, który pozwala nam reprezentować przekształcenia afiniczne, a nie tylko liniowe.* \n",
    "\n",
    "**Rozwiązanie:** Potrzebujemy więc funkcji, która \"spłaszczy\" nam przedział $\\mathbb{R}$ do $[0, 1]$. Można by taką funkcję znaleźć na wiele sposobów, ale z powodów technicznych najczęściej korzysta się z sigmoidy, tzn.:\n",
    "$$ \\sigma(x) = \\frac{1}{1 + \\exp(-x)} $$\n",
    "\n",
    "**Wykres funkcji sigmoid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.098207Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"sigma(x)\")\n",
    "\n",
    "X = np.linspace(-6, 6)\n",
    "plt.plot(X, 1 / (1 + np.exp(-X)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatecznie nasz model wygląda tak:\n",
    "$$\n",
    "    \\hat{p}(y = 1 \\mid x) = \\sigma(w^Tx + b)\n",
    "$$\n",
    "\n",
    "Mamy więc model, który jest w stanie dać nam rozkład prawdopodobieństwa etykiety pod warunkiem $\\hat{p}(y \\mid x)$. Nasz zbiór treningowy zawiera też próbki z prawdziwego rozkładu prawdopodobieństwa: $p(y_i \\mid x_i)$.\n",
    "\n",
    "Jako funkcję kosztu wybieramy sobie więc \"różnicę\" pomiędzy prawdziwym rozkładem, a rozkładem zadanym przez nasz model. W tym wypadku sprawdza się **entropia krzyżowa** (cross-entropy), zadana wzorem:\n",
    "\n",
    "\n",
    "\\begin{split}\n",
    "      \\mathcal{H}(p(y \\mid x_i), \\hat{p}(y \\mid x_i)) &= -\\sum_{k \\in \\{0, 1\\}} p(y=k \\mid x_i) \\ln \\hat{p}(y=k \\mid x_i) \\\\\n",
    "      &= -p(y = 0 \\mid x_i) \\ln \\hat{p}(y = 0 \\mid x_i) - p(y=1 \\mid x_i) \\ln \\hat{p}(y=1 \\mid x_i) \\\\\n",
    "      &= -(1 - p(y = 1 \\mid x_i)) \\ln (1 - \\hat{p}(y = 1 \\mid x_i)) - p(y=1 \\mid x_i) \\ln \\hat{p}(y=1 \\mid x_i) \\\\\n",
    "      &= - (1 - y_i) \\ln (1 - \\hat{y}) - y_i \\ln \\hat{y} ,\n",
    "\\end{split}\n",
    "gdzie podstawiliśmy sobie: $$\\hat{p}(y=1 \\mid x_i) = \\hat{y}, \\\\ p(y=1 \\mid x_i) = y_i$$\n",
    "\n",
    "Ustalmy teraz, że ostateczną funkcją kosztu naszego modelu będzie średnia entropia krzyżowa dla zbioru danych:\n",
    "$$\n",
    "    \\mathcal{L}(X) = \\frac{1}{N} \\sum_{(x_i, y_i) \\in X}^N  \\mathcal{H}(p(y \\mid x_i), \\hat{p}(y \\mid x_i))\n",
    "$$\n",
    "\n",
    "\n",
    "Taki model możemy teraz optymalizować metodą spadku gradientu i wykorzystać do klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.099522Z"
    }
   },
   "outputs": [],
   "source": [
    "# Przygotujmy datasety i funkcje pomocnicze\n",
    "dataset_1d = utils.get_classification_dataset_1d()\n",
    "dataset_2d = utils.get_classification_dataset_2d()\n",
    "\n",
    "\n",
    "def calculate_accuracy(\n",
    "    logistic_reg: \"LogisticRegression\", X: torch.Tensor, y: torch.Tensor\n",
    ") -> float:\n",
    "    preds = logistic_reg.predict(X)\n",
    "    correct_n = (preds == y).float().sum().item()\n",
    "    return float(correct_n / len(y))\n",
    "\n",
    "\n",
    "def plot_dataset_1d(logistic_reg: \"LogisticRegression\", dataset_1d: utils.Dataset) -> None:\n",
    "    plt.scatter(dataset_1d.data[:10], [0.5] * 10, c=\"purple\", label=\"0\")\n",
    "    plt.scatter(dataset_1d.data[10:], [0.5] * 10, c=\"yellow\", label=\"1\")\n",
    "    linspace = torch.linspace(-7.5, 15, steps=100).view(-1, 1)\n",
    "    plt.plot(\n",
    "        linspace.numpy().ravel(),\n",
    "        logistic_reg.predict_proba(linspace).detach().numpy(),\n",
    "        label=\"p(y=1 | x)\",\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_dataset_2d(logistic_reg: \"LogisticRegression\", dataset_2d: utils.Dataset) -> None:\n",
    "    plt.scatter(dataset_2d.data[:50, 0], dataset_2d.data[:50, 1], c=\"purple\", label=\"0\")\n",
    "    plt.scatter(dataset_2d.data[50:, 0], dataset_2d.data[50:, 1], c=\"yellow\", label=\"1\")\n",
    "\n",
    "    linspace_x = torch.linspace(-4, 7, steps=100)\n",
    "    linspace_y = (-logistic_reg.bias - logistic_reg.weight[0] * linspace_x) / logistic_reg.weight[1]\n",
    "\n",
    "    linspace_y = linspace_y.detach().numpy()\n",
    "    plt.plot(linspace_x.detach().numpy(), linspace_y, label=\"Granica decyzyjna\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 (2 pkt.)\n",
    "\n",
    "Zaimplementuj w PyTorchu regresję logistyczną. W tym celu trzeba napisać następujące funkcje:\n",
    "1. Funkcję kosztu modelu regresji logistycznej `loss(X, y)`, według następujących kroków:\n",
    "    * Policz model liniowy $z = w^Tx + b$\n",
    "    * Na wektorze $z$ zaimplementuj funkcję $\\hat{y} = \\sigma(z) = \\frac{1}{1 + \\exp(-z)}$.\n",
    "    * Policz entropię krzyżową pomiędzy predykcjami $\\hat{y}$ a etykietami $y$ zadaną przez:\n",
    "    $\\frac{1}{N} \\sum_i - (1 - y_i) \\ln (1 - \\hat{y}_i) - y_i \\ln \\hat{y}_i$\n",
    "2. Funkcję `predict_proba(X)` zwracającą dla każdego $x_i \\in X$ zadane przez nasz model prawdopodobieństwo $\\hat{p}(y = 1 \\mid x_i)$. \n",
    "3. Funkcję `predict(X)` zwracającą dla każdego $x_i \\in X$ przewidywaną etykietę (tzn. $0$ albo $1$). Zwracana etykieta powinna być typu `float`.\n",
    "\n",
    "**UWAGA** Nie można korzystać z funkcji PyTorcha do liczenia entropii krzyżowej (np. `torch.nn.BCELoss`) ani sigmoidy (np.`torch.nn.functional.Sigmoid`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.100823Z"
    }
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, input_dim: int) -> None:\n",
    "        self.input_dim = input_dim\n",
    "        self.weight = torch.randn(self.input_dim, requires_grad=True)\n",
    "        self.bias = torch.randn((), requires_grad=True)\n",
    "\n",
    "    def _sigmoid(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ...\n",
    "\n",
    "    def fit(\n",
    "        self, X: torch.Tensor, y: torch.Tensor, lr: float = 1e-6, num_steps: int = int(1e4)\n",
    "    ) -> None:\n",
    "        self.weight = torch.randn(self.input_dim, requires_grad=True)\n",
    "        self.bias = torch.randn((), requires_grad=True)\n",
    "        for idx in range(num_steps):\n",
    "            self.weight.requires_grad = True\n",
    "            self.bias.requires_grad = True\n",
    "\n",
    "            loss_val = self.loss(X, y)\n",
    "            loss_val.backward()\n",
    "\n",
    "            w_grad = self.weight.grad\n",
    "            b_grad = self.bias.grad\n",
    "            with torch.no_grad():\n",
    "                self.weight = self.weight - lr * w_grad\n",
    "                self.bias = self.bias - lr * b_grad\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_proba(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        ...\n",
    "\n",
    "    def predict(self, X: torch.Tensor) -> torch.FloatTensor:\n",
    "        ...\n",
    "\n",
    "    def loss(self, X: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.102704Z"
    }
   },
   "outputs": [],
   "source": [
    "checker.check_04_logistic_reg(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.103474Z"
    }
   },
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(1)\n",
    "logistic_reg.fit(dataset_1d.data, dataset_1d.target, lr=1e-3, num_steps=int(2e4))\n",
    "acc = calculate_accuracy(logistic_reg, dataset_1d.data, dataset_1d.target)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "plot_dataset_1d(logistic_reg, dataset_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T15:37:08.104586Z",
     "start_time": "2023-10-30T15:37:08.104295Z"
    }
   },
   "outputs": [],
   "source": [
    "logistic_reg = LogisticRegression(2)\n",
    "logistic_reg.fit(dataset_2d.data, dataset_2d.target, lr=1e-2, num_steps=int(2e4))\n",
    "acc = calculate_accuracy(logistic_reg, dataset_2d.data, dataset_2d.target)\n",
    "print(\"Accuracy\", acc)\n",
    "\n",
    "plot_dataset_2d(logistic_reg, dataset_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Część 2: Reguła łańcuchowa i automatyczne różniczkowanie\n",
    "\n",
    "Przypomnijmy sobie regułę łańcuchową liczenia pochodnych. Jeśli mamy:\n",
    "$$ L(x) = g(f(x)), $$ \n",
    "to wtedy:\n",
    "\n",
    "$$ \\frac{dL(x)}{dx} = \\frac{dL(x)}{df(x)}\\frac{df(x)}{dx} $$\n",
    "\n",
    "W kontekście automatycznego różniczkowania w PyTorchu kluczowa jest tu właściwość, że do policzenia gradientu nie musimy nic wiedzieć o $g(x)$ o ile tylko znamy $\\frac{dL(x)}{df(x)}$. **Każdy moduł wie, jak policzyć swój gradient i dzięki temu można łańcuchowo liczyć pochodne skomplikowanych funkcji.**\n",
    "\n",
    "\n",
    "W PyTorchu każda funkcja, której używamy, ma zaimplementowane dwa podmoduły:\n",
    "* **Forward** - na podstawie podanego $x$ potrafi obliczyć $f(x)$. \n",
    "* **Backward** - na podstawie podanego $\\frac{dL(x)}{df(x)}$ potrafi policzyć $\\frac{dL(x)}{dx}$.\n",
    "\n",
    "Więcej o automatycznym różniczkowaniu można przeczytać w [dokumentacji PyTorcha](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.105012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Przygotujmy sobie dane do testów\n",
    "input = torch.randn(30, 20, dtype=torch.double, requires_grad=True) * 3\n",
    "a = torch.randn(20, 30, requires_grad=True).double() * 2 - 5\n",
    "b = torch.randn(20, 30, requires_grad=True).double() + 6\n",
    "\n",
    "\n",
    "preds = torch.rand(30, requires_grad=True).double()\n",
    "labels_dist = torch.distributions.Bernoulli(probs=0.7)\n",
    "labels = labels_dist.sample([30]).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykład: różniczkowanie mnożenia\n",
    "Chcemy zaimplementować od nowa w PyTorchu fukcję $f(a, b) = a \\cdot b$, która potrafi policzyć swoje pochodne.\n",
    "\n",
    "W efekcie implementujemy obiekt typu `torch.autograd.Function` z metodami:\n",
    "* **Forward** \n",
    "    1. Dostaje na wejściu `a` oraz `b`\n",
    "    1. Zapamiętuje `a` oraz `b`, które przydadzą się później przy liczeniu pochodnej\n",
    "    2. Zwraca `a * b`\n",
    "* **Backward**\n",
    "    1. Dostaje na wejściu `grad_output` reprezentujące wartość $\\frac{dL(x)}{df(a, b)}$.\n",
    "    2. Wyjmuje z pamięci `a` oraz `b`.\n",
    "    3. Liczy swoją pochodną po a: $\\frac{df(a, b)}{da} = \\frac{da}{da} \\cdot b + a \\cdot \\frac{db}{da} = 1\\cdot b + a\\cdot 0 = b$\n",
    "    4. Liczy swoją pochodną po b: $\\frac{df(a, b)}{db} = \\frac{da}{db} \\cdot b + a \\cdot \\frac{db}{db} = 0\\cdot b + a\\cdot 1 = a$\n",
    "    5. Zwraca pochodne $\\frac{dL(x)}{df(a, b)} \\frac{df(a, b)}{da}$ oraz $\\frac{dL(x)}{df(a, b)} \\frac{df(a, b)}{db}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T15:37:08.106322Z",
     "start_time": "2023-10-30T15:37:08.105672Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyProduct(torch.autograd.Function):  # type: ignore\n",
    "    @staticmethod\n",
    "    def forward(self, a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:  # type: ignore\n",
    "        self.save_for_backward(a, b)\n",
    "        return a * b\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:  # type: ignore\n",
    "        # Wyjmujemy z pamięci a oraz b\n",
    "        a, b = self.saved_tensors\n",
    "        # Liczymy pochodną po a\n",
    "        a_grad = b\n",
    "        # Liczymy pochodną po b\n",
    "        b_grad = a\n",
    "\n",
    "        # Zwracamy \"łańcuchowe\" pochodne\n",
    "        return grad_output * a_grad, grad_output * b_grad\n",
    "\n",
    "\n",
    "prod_fn = MyProduct.apply\n",
    "torch.autograd.gradcheck(prod_fn, (a, b), eps=1e-3, atol=1e-2, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 (3 pkt.)\n",
    "Proszę zaimplementować backward pass w następujących funkcjach:\n",
    "* MyAdd(a, b): a + b - $\\frac{df}{da} = 1, \\frac{df}{db} = 1$\n",
    "* MyDiv(a, b): a / b - $\\frac{df}{da} = \\frac{1}{b}, \\frac{df}{db}= -\\frac{a}{b^2}$\n",
    "* MySigmoid(input): tak jak w zadaniu 2  - $\\frac{df}{dz} = \\sigma(z)(1 - \\sigma(z)) = \\frac{1}{1 + \\exp(-z)} \\cdot (1 - \\frac{1}{1 + \\exp(-z))})$\n",
    "* BCE(preds, labels): tak jak w zadaniu 2 - $\\frac{df}{d\\hat{y}} = \\frac{1}{N} (-\\frac{y}{\\hat{y}} + \\frac{1 - y}{1 - \\hat{y}}),$ gdzie $y$ to etykieta a $\\hat{y}$ to predykcja.\n",
    "\n",
    "(jako że nie liczymy tutaj pochodnej po etykietach, można zwrócić `grad_labels = None`)\n",
    "\n",
    "**Zdarza się, że funkcja do testowania gradientu `torch.autograd.gradcheck` będzie wyrzucała błędy przez niedokładności numeryczne. Proszę odświeżyć dane i spróbować jeszcze raz.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T15:37:08.106403Z",
     "start_time": "2023-10-30T15:37:08.106376Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyAdd(torch.autograd.Function):  # type: ignore\n",
    "    @staticmethod\n",
    "    def forward(self, a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:  # type: ignore\n",
    "        self.save_for_backward(a, b)\n",
    "        ...\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:  # type: ignore\n",
    "        a, b = self.saved_tensors\n",
    "        ...\n",
    "\n",
    "\n",
    "add_fn = MyAdd.apply\n",
    "torch.autograd.gradcheck(add_fn, (a, b), eps=1e-3, atol=1e-2, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.107102Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDiv(torch.autograd.Function):  # type: ignore\n",
    "    @staticmethod\n",
    "    def forward(self, a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:  # type: ignore\n",
    "        self.save_for_backward(a, b)\n",
    "        ...\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:  # type: ignore\n",
    "        a, b = self.saved_tensors\n",
    "        ...\n",
    "\n",
    "\n",
    "div_fn = MyDiv.apply\n",
    "torch.autograd.gradcheck(div_fn, (a, b), eps=1e-3, atol=1e-2, rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.107828Z"
    }
   },
   "outputs": [],
   "source": [
    "class MySigmoid(torch.autograd.Function):  # type: ignore\n",
    "    @staticmethod\n",
    "    def forward(self, input_: torch.Tensor) -> torch.Tensor:  # type: ignore\n",
    "        self.save_for_backward(input_)\n",
    "        ...\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output: torch.Tensor) -> torch.TensorType:  # type: ignore\n",
    "        (input_,) = self.saved_tensors\n",
    "        ...\n",
    "\n",
    "\n",
    "sigmoid_fn = MySigmoid.apply\n",
    "torch.autograd.gradcheck(sigmoid_fn, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.108772Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyBinaryCrossEntropy(torch.autograd.Function):  # type: ignore\n",
    "    @staticmethod\n",
    "    def forward(\n",
    "        self, preds: torch.Tensor, labels: torch.Tensor, bias: torch.Tensor | None = None  # type: ignore\n",
    "    ) -> torch.Tensor:\n",
    "        self.save_for_backward(preds, labels)\n",
    "        ...\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_output: torch.Tensor) -> torch.Tensor:  # type: ignore\n",
    "        preds, labels = self.saved_tensors\n",
    "        ...\n",
    "\n",
    "\n",
    "bce_fn = MyBinaryCrossEntropy.apply\n",
    "torch.autograd.gradcheck(bce_fn, (preds, labels), eps=1e-3, atol=1e-2, rtol=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy nasze moduły w prostej pętli treningowej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.109761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Przygotowujemy prosty dataset\n",
    "X = torch.cat([torch.randn(10) * 3 + 2, torch.randn(10) * 3 + 12])\n",
    "y = torch.cat([torch.zeros(10), torch.ones(10)])\n",
    "\n",
    "\n",
    "# Inicjalizujemy zmienne\n",
    "weight = torch.randn((), requires_grad=True)\n",
    "bias = torch.randn((), requires_grad=True)\n",
    "\n",
    "lr = 1e-1\n",
    "for idx in range(10000):\n",
    "    weight.requires_grad = True\n",
    "    bias.requires_grad = True\n",
    "\n",
    "    # Liczymy funkcję kosztu za pomocą naszych modułów\n",
    "    logit = add_fn(prod_fn(weight, X), bias)\n",
    "    pred = sigmoid_fn(logit)\n",
    "    loss = bce_fn(pred, y)\n",
    "\n",
    "    # Gradient przechodzi przez funkcję backward każdego modułu\n",
    "    loss.backward()\n",
    "\n",
    "    # Wyciągamy gradienty\n",
    "    w_grad = weight.grad\n",
    "    b_grad = bias.grad\n",
    "\n",
    "    # Wykonujemy krok metody spadku gradientu\n",
    "    with torch.no_grad():\n",
    "        weight = weight - lr * w_grad\n",
    "        bias = bias - lr * b_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-30T15:37:08.110836Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, np.zeros_like(X) + 0.5, c=y.numpy())\n",
    "\n",
    "linspace = torch.linspace(-5, 15, steps=100).view(-1, 1)\n",
    "with torch.no_grad():\n",
    "    plt.plot(\n",
    "        linspace.numpy().ravel(),\n",
    "        sigmoid_fn(add_fn(prod_fn(weight, linspace), bias)).detach().numpy(),\n",
    "        label=\"p(y=0 | x)\",\n",
    "    )\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dygresje\n",
    "* Istnieją inne frameworki do deep learningu poza PyTorchem. Szczególnie popularny jest teraz TensorFlow (często używany razem z Kerasem). Popularne w przeszłości, ale wciąż poniekąd istotne są: Theano, Caffe, MXNet, Jax.\n",
    "* Sigmoid staje się bardziej naturalny, kiedy myślimy o outputach z modelu liniowego jako o logarytmie szans (*log-odds* albo *logits*). [Więcej tutaj](https://en.wikipedia.org/wiki/Logistic_regression#Logistic_model). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
