{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import cos, sin\n",
    "\n",
    "import checker\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Po co nam to numpy?\n",
    "Przydaje nam się z kilku powodów:\n",
    "* Napisanie jednej linijki w numpy jest szybsze i wygodniejsze niż napisanie pętli, jest też mniejsza szansa, że zrobimy gdzieś po drodze błąd. Oczywiście najpierw trzeba się przyzwyczaić do intefejsu.\n",
    "* Numpy jest znacznie bardziej wydajny niż napisane przez nas funkcje w \"czystym\" Pythonie.\n",
    "* PyTorch, biblioteka do głębokiego uczenia, z której później będziemy korzystać, ma bardzo podobny interfejs."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Kilka przykładów"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "X = [random.random() for _ in range(10000)]\n",
    "y = [sin(x) + cos(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "X = np.random.random(10000)\n",
    "y = np.sin(X) + np.cos(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def almost_variance(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Oblicza 1/n * SUM (x_i - mean(x))^4\"\"\"\n",
    "    m = sum(x) / len(x)\n",
    "    result = 0\n",
    "    for i in range(len(x)):\n",
    "        result += (x[i] - m) ** 4\n",
    "    result /= len(x)\n",
    "    return result\n",
    "\n",
    "\n",
    "def numpy_almost_var(x: np.ndarray) -> np.ndarray:\n",
    "    m = np.mean(x)\n",
    "    powers = (x - m) ** 4\n",
    "    return np.mean(powers)\n",
    "\n",
    "\n",
    "X = np.random.random(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "almost_variance(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "numpy_almost_var(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1. (3 pkt.)\n",
    "Wykonać poniższe ćwiczenia przy pomocy Numpy:\n",
    "\n",
    "1. Wykorzystując `broadcasting` (patrz na rysunek poniżej) stwórz funkcję, która dla zadnego $K$ zwraca tabliczkę mnożenia, tzn. tablicę $A$ taką, że: $$A_{ij} = i \\cdot j\\;\\;\\;\\;\\; \\forall i,j \\in \\{1,\\dots,K\\}$$\n",
    "    <img src=\"http://www.astroml.org/_images/fig_broadcast_visual_1.png\">\n",
    "\n",
    "    Przydatne funkcje: `np.arange`, `np.reshape`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplication_table(k: int) -> np.ndarray:\n",
    "    ...\n",
    "\n",
    "\n",
    "print(\"Wynik funkcji multiplication:\\n\", multiplication_table(10))\n",
    "checker.check_multiplication_table(multiplication_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Mając daną tablice jednowymiarową oraz liczbę `x` znajdź najbliższą wartość `x` w `A`, tzn. \n",
    "    $$ \\mathrm{closest}(x, A) = \\arg\\min_{a\\in A}|x - a|  $$\n",
    "\n",
    "    Przydatne funkcje: `np.argmin`, `np.abs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest(x: float, A: np.ndarray) -> np.ndarray:\n",
    "    ...\n",
    "\n",
    "\n",
    "print(\"Wynik funkcji closest:\", closest(9, np.array([5, 8, 14])))\n",
    "checker.check_closest(closest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Zaimplementuj proste liczenie wartosci wielomianu o zadanych współczynnikach (analogię `np.poly1d`), czyli funkcję\n",
    "\n",
    "    $$\n",
    "    \\mathrm{poly}(x, a) = a_0 + a_1 x + a_2 x^2 + \\dots + a_k x^k = \\sum_{i=1}^k a_i x^i\n",
    "    $$\n",
    "\n",
    "    Potencjalnie przydatne funkcje: `np.cumprod`, `np.concatenate`, `np.sum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly(x: int, a: np.ndarray) -> np.ndarray:\n",
    "    ...\n",
    "\n",
    "\n",
    "print(\"Wynik funkcji poly:\", poly(3, np.array([1, 2, 4])))\n",
    "checker.check_poly(poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2. (2 pkt.)\n",
    "Dla macierzy $X$ o wymiarze `[N, D]` zaimplementować operację whiteningu: \n",
    "\n",
    "$\\mathrm{whiten}(X) = (X-\\mathrm{mean} X)(\\mathrm{cov} X)^{-1/2}$\n",
    "\n",
    "$\\mathrm{mean} X$ rozumiemy jako wektor wierszowy, którego każdy element jest zdefiniowany jako: $$(\\mathrm{mean}X)_i = \\frac{1}{N} \\sum_{j=1}^N X_{ij}$$\n",
    "\n",
    "**Uwaga 1: np.cov przyjmuje, że każdy wiersz macierzy to osobna cecha, a każda kolumna to osobna obserwacja - czyli odwrotnie niż u nas. Dlatego przed podaniem naszej macierzy do np.cov trzeba ją transponować.**\n",
    "\n",
    "**Uwaga 2: pierwiastek z macierzy to nie to samo co pierwiastkowanie element-wise, takie jak w np.sqrt. Najlepiej poszukać odpowiedniej funkcji w bibliotece scipy i ją zaimportować.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.linalg import ???\n",
    "\n",
    "\n",
    "def whiten(X: np.ndarray) -> np.ndarray:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_diag_normal = np.random.multivariate_normal([-5, 2.0], [[10, 0], [0, 0.5]], size=200)\n",
    "X_multivariate_normal = np.random.multivariate_normal([-5, -2], [[1, 0.99], [0.99, 1]], size=500)\n",
    "X_uniform = np.random.normal(6, 5, size=(50, 2))\n",
    "X_gmm = np.concatenate((X_multivariate_normal, X_diag_normal), axis=0)\n",
    "\n",
    "utils.scatter_with_whiten(X_diag_normal, whiten, name=\"Independent normal distribution\")\n",
    "utils.scatter_with_whiten(X_multivariate_normal, whiten, name=\"Multivariate normal distribution\")\n",
    "utils.scatter_with_whiten(X_uniform, whiten, name=\"Uniform distribution\")\n",
    "utils.scatter_with_whiten(X_gmm, whiten, name=\"Gaussian mixture distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standaryzacja a whitening\n",
    "W pierwszym notebooku implementowaliśmy następującą funkcję, która wykonuje zadanie podobne do whiteningu:\n",
    "\n",
    "$$ f(x_{ij}) = \\frac{x_{ij} - \\mu_j}{\\sigma_j} $$\n",
    "\n",
    "Tę funkcję nazwijmy **standaryzacją**. Czym zatem różni się standaryzacja od whiteningu? Czy nie wystarczy znormalizować kolumn i zamiast tego musimy wykonywać znacznie bardziej kosztowną operację liczenia i odwracania macierzy kowariancji?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.scatter_with_whiten(\n",
    "    X_diag_normal, whiten, name=\"Independent normal distribution\", standarize=True\n",
    ")\n",
    "utils.scatter_with_whiten(\n",
    "    X_multivariate_normal, whiten, name=\"Multivariate normal distribution\", standarize=True\n",
    ")\n",
    "utils.scatter_with_whiten(X_uniform, whiten, name=\"Uniform distribution\", standarize=True)\n",
    "utils.scatter_with_whiten(X_gmm, whiten, name=\"Gaussian mixture distribution\", standarize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3. (2 pkt.)\n",
    "Należy:\n",
    "1. Wysamplować $10000$ przykładów z rozkładu normalnego $\\mathcal{N}(\\mu, \\sigma)$. **Należy wybrać niestandardowe parametry**, tzn. $\\mu \\neq 0$ oraz $\\sigma \\neq 1$.\n",
    "2. Następnie należy policzyć, jaki procent wylosowanych przykładów, znajduje się od środka w odległości większej niż: \n",
    "    * $1\\sigma$ (tzn. $|x - \\mu| > 1\\sigma$)\n",
    "    * $2\\sigma$ (tzn. $|x - \\mu| > 2\\sigma$)\n",
    "    * $3\\sigma$ (tzn. $|x - \\mu| > 3\\sigma$)\n",
    "    \n",
    "3. Wypisać wszystkie przykłady, które wpadają do ostatniej kategorii (tzn. są oddalone o co najmniej $3\\sigma$ od średniej)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podpunkt 1: Wysamplować 10000 przykładów z rozkładu normalnego\n",
    "loc = ???  # średnia wybranego rozkładu normalnego\n",
    "scale = ???  # odchylenie standardowe wybranego rozkładu normalnego\n",
    "X = np.random.normal(???)\n",
    "\n",
    "# Podpunkt 2: Wyliczyć i wypisać procent \n",
    "\n",
    "# Podpunkt 3: Wypisać elementy, które są oddalone od średniej o 3 sigma.\n",
    "\n",
    "# Trochę wizualizacji\n",
    "utils.visualize_normal_dist(X, loc, scale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
